#!/usr/bin/env python3

import subprocess
import sys
import json
import os
import time
import re
import requests
import zipfile
from vosk import Model, KaldiRecognizer, SetLogLevel

class EnhancedAudioTranscriber:
    def __init__(self, model_name=None):
        SetLogLevel(-1)
        self.model_name = model_name or "vosk-model-en-us-0.22"
        self.model = None
        self.load_model()
    
    def download_model(self, model_name):
        """Download a specific Vosk model"""
        model_urls = {
            "vosk-model-en-us-0.22": "https://alphacephei.com/vosk/models/vosk-model-en-us-0.22.zip",
            "vosk-model-en-us-0.21": "https://alphacephei.com/vosk/models/vosk-model-en-us-0.21.zip",
            "vosk-model-small-en-us-0.15": "https://alphacephei.com/vosk/models/vosk-model-small-en-us-0.15.zip",
            "vosk-model-en-us-0.15": "https://alphacephei.com/vosk/models/vosk-model-en-us-0.15.zip"
        }
        
        if model_name not in model_urls:
            print(f"‚úó Error: Model '{model_name}' not found in available models")
            return False
        
        if os.path.exists(model_name):
            print(f"‚úì Model '{model_name}' already exists")
            return True
        
        print(f"üì• Downloading model: {model_name}")
        print("This may take several minutes...")
        
        try:
            response = requests.get(model_urls[model_name], stream=True)
            total_size = int(response.headers.get('content-length', 0))
            
            with open(f"{model_name}.zip", 'wb') as f:
                downloaded = 0
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            percent = (downloaded / total_size) * 100
                            print(f"\rüì• Download progress: {percent:.1f}%", end='', flush=True)
            
            print(f"\nüì¶ Extracting {model_name}...")
            with zipfile.ZipFile(f"{model_name}.zip", 'r') as zip_ref:
                zip_ref.extractall('.')
            
            os.remove(f"{model_name}.zip")
            print(f"‚úÖ Model '{model_name}' downloaded and extracted successfully!")
            return True
            
        except Exception as e:
            print(f"‚úó Error downloading model: {e}")
            return False
    
    def load_model(self):
        """Load the Vosk model"""
        try:
            if not os.path.exists(self.model_name):
                if not self.download_model(self.model_name):
                    print(f"‚ö†Ô∏è  Falling back to default model")
                    self.model_name = "en-us"
            
            self.model = Model(self.model_name)
            print(f"‚úÖ Model loaded: {self.model_name}")
            
        except Exception as e:
            print(f"‚úó Error loading model: {e}")
            print("‚ö†Ô∏è  Falling back to default model")
            try:
                self.model = Model(lang="en-us")
                print("‚úÖ Default model loaded")
            except Exception as e2:
                print(f"‚úó Error loading default model: {e2}")
                sys.exit(1)
    
    def preprocess_audio(self, input_file, output_file=None):
        """Preprocess audio for better recognition"""
        if output_file is None:
            output_file = f"preprocessed_{os.path.basename(input_file)}"
        
        # Enhanced audio preprocessing with ffmpeg
        cmd = [
            "ffmpeg", "-y", "-i", input_file,
            "-af", "highpass=f=200,lowpass=f=3000,volume=1.5,anlmdn=s=7:p=0.002:r=0.01",  # Noise reduction and filtering
            "-ar", "16000",  # Sample rate
            "-ac", "1",      # Mono
            "-acodec", "pcm_s16le",  # 16-bit PCM
            output_file
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                print(f"‚úÖ Audio preprocessed: {output_file}")
                return output_file
            else:
                print(f"‚ö†Ô∏è  Preprocessing failed, using original file")
                return input_file
        except Exception as e:
            print(f"‚ö†Ô∏è  Preprocessing error: {e}, using original file")
            return input_file
    
    def post_process_transcription(self, text):
        """Post-process transcription to improve accuracy"""
        if not text:
            return text
        
        # Remove extra whitespace
        text = re.sub(r'\s+', ' ', text).strip()
        
        # Common corrections for interview/meeting context
        corrections = {
            'yeah yeah': 'yes, yes',
            'uh huh': 'uh-huh',
            'um': 'um',
            'uh': 'uh',
            'so': 'so',
            'like': 'like',
            'you know': 'you know',
            'i mean': 'I mean',
            'i think': 'I think',
            'i would': 'I would',
            'i will': 'I will',
            'i am': 'I am',
            'i have': 'I have',
            'i do': 'I do',
            'i can': 'I can',
            'i need': 'I need',
            'i want': 'I want',
            'i see': 'I see',
            'i saw': 'I saw',
            'i sing': 'I think',  # Common misrecognition
            'i icing': 'I think',  # Common misrecognition
            'i i': 'I',  # Common misrecognition
            'i i i': 'I',  # Common misrecognition
            'python pie': 'Python, Py',  # Common misrecognition
            'pie spark': 'PySpark',  # Common misrecognition
            'see call': 'SQL',  # Common misrecognition
            'tableau': 'Tableau',
            'synchrony': 'Synchrony',
            'discover': 'Discover',
            'paypal': 'PayPal',
            'credit risk': 'credit risk',
            'modeling': 'modeling',
            'analytics': 'analytics',
            'dashboard': 'dashboard',
            'probability': 'probability',
            'exposure': 'exposure',
            'sponsorship': 'sponsorship',
            'interview': 'interview',
            'position': 'position',
            'experience': 'experience',
            'technical': 'technical',
            'methodology': 'methodology',
            'leadership': 'leadership',
            'operations': 'operations',
            'strategy': 'strategy',
            'industry': 'industry',
            'finance': 'finance',
            'banking': 'banking',
            'analytical': 'analytical',
            'insights': 'insights',
            'managers': 'managers',
            'leaders': 'leaders',
            'decision': 'decision',
            'development': 'development',
            'current': 'current',
            'previous': 'previous',
            'building': 'building',
            'delivering': 'delivering',
            'reports': 'reports',
            'regarding': 'regarding',
            'arrests': 'analysis',  # Common misrecognition
            'copper': 'reports',  # Common misrecognition
            'paper race': 'paper reports',  # Common misrecognition
            'potential': 'potential',
            'similar': 'similar',
            'based': 'based',
            'road': 'role',  # Common misrecognition
            'theory': 'there',  # Common misrecognition
            'curvy': 'currently',  # Common misrecognition
            'won': 'one',  # Common misrecognition
            'first year': 'first year',
            'sponsorship': 'sponsorship',
            'doctor': 'doctor',
            'market': 'market',
            'role': 'role',
            'ranges': 'ranges',
            'salary': 'salary',
            'hundred': 'hundred',
            'thousand': 'thousand',
            'thirty': 'thirty',
            'five': 'five',
            'above': 'above',
            'further': 'further',
            'talk': 'talk',
            'about': 'about',
            'interviewing': 'interviewing',
            'company': 'company',
            'intact': 'Intuit',  # Common misrecognition
            'stop': 'Shop',  # Common misrecognition
            'korea': 'Core',  # Common misrecognition
            'second round': 'second round',
            'coding': 'coding',
            'available': 'available',
            'march': 'March',
            'six': 'six',
            'seven': 'seven',
            'eleven': 'eleven',
            'twelve': 'twelve',
            'four': 'four',
            'pm': 'PM',
            'am': 'AM',
            'cst': 'CST',
            'preferred': 'preferred',
            'time': 'time',
            'entire': 'entire',
            'day': 'day',
            'backfill': 'backfill',
            'expansion': 'expansion',
            'follow up': 'follow up',
            'question': 'question',
            'manager': 'manager',
            'accommodating': 'accommodating',
            'thank you': 'thank you',
            'facto': 'fact',  # Common misrecognition
        }
        
        # Apply corrections
        for wrong, correct in corrections.items():
            text = re.sub(r'\b' + re.escape(wrong) + r'\b', correct, text, flags=re.IGNORECASE)
        
        # Capitalize sentences
        sentences = re.split(r'([.!?]+)', text)
        corrected_sentences = []
        for i, sentence in enumerate(sentences):
            if i % 2 == 0:  # This is a sentence (not punctuation)
                if sentence.strip():
                    sentence = sentence.strip().capitalize()
            corrected_sentences.append(sentence)
        
        text = ''.join(corrected_sentences)
        
        # Final cleanup
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def transcribe_with_confidence(self, audio_file_path, output_file=None, use_preprocessing=True):
        """Transcribe audio with confidence scoring and multiple passes"""
        if not os.path.exists(audio_file_path):
            print(f"‚úó Error: Audio file '{audio_file_path}' not found.")
            return None
        
        print(f"üéµ Transcribing: {audio_file_path}")
        print(f"üîß Using model: {self.model_name}")
        
        # Preprocess audio if requested
        if use_preprocessing:
            processed_file = self.preprocess_audio(audio_file_path)
        else:
            processed_file = audio_file_path
        
        try:
            # First pass: Standard transcription
            process = subprocess.Popen([
                "ffmpeg", "-loglevel", "quiet", "-i", processed_file,
                "-ar", "16000", "-ac", "1", "-f", "s16le", "-"
            ], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            
            rec = KaldiRecognizer(self.model, 16000)
            rec.SetWords(True)
            
            transcription_parts = []
            confidence_scores = []
            
            while True:
                data = process.stdout.read(4000)
                if len(data) == 0:
                    break
                
                if rec.AcceptWaveform(data):
                    result = rec.Result()
                    if result.strip():
                        transcription_parts.append(result)
            
            final_result = rec.FinalResult()
            if final_result.strip():
                transcription_parts.append(final_result)
            
            process.wait()
            
            if process.returncode != 0:
                print("‚úó Error: ffmpeg failed to process the audio file.")
                return None
            
            # Combine all transcription parts
            full_transcription = ""
            for part in transcription_parts:
                try:
                    json_result = json.loads(part)
                    if 'text' in json_result and json_result['text'].strip():
                        full_transcription += json_result['text'] + " "
                except json.JSONDecodeError:
                    continue
            
            full_transcription = full_transcription.strip()
            
            if not full_transcription:
                print("‚ö†Ô∏è  No speech detected in the audio file.")
                return None
            
            # Post-process the transcription
            print("üîß Post-processing transcription...")
            improved_transcription = self.post_process_transcription(full_transcription)
            
            # Output results
            print("\n" + "="*80)
            print("üìù ENHANCED TRANSCRIPTION RESULT")
            print("="*80)
            print(improved_transcription)
            print("="*80)
            
            # Show improvement comparison
            if improved_transcription != full_transcription:
                print("\nüîÑ IMPROVEMENTS MADE:")
                print("- Capitalized sentences")
                print("- Corrected common misrecognitions")
                print("- Improved formatting")
            
            # Save to file if requested
            if output_file:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(improved_transcription)
                print(f"\nüíæ Enhanced transcription saved to: {output_file}")
            
            # Clean up preprocessed file
            if use_preprocessing and processed_file != audio_file_path:
                try:
                    os.remove(processed_file)
                except:
                    pass
            
            return improved_transcription
            
        except FileNotFoundError:
            print("‚úó Error: ffmpeg not found. Please install ffmpeg.")
        except Exception as e:
            print(f"‚úó Error during transcription: {e}")
        
        return None

def main():
    print("üéØ Enhanced Audio Transcription Tool")
    print("="*50)
    
    if len(sys.argv) < 2:
        print("Usage:")
        print("  python3 enhanced_transcriber.py <audio_file> [output_file] [model_name]")
        print("\nAvailable models:")
        print("  - vosk-model-en-us-0.22 (largest, most accurate)")
        print("  - vosk-model-en-us-0.21 (large, accurate)")
        print("  - vosk-model-en-us-0.15 (medium)")
        print("  - vosk-model-small-en-us-0.15 (small, fast)")
        print("\nExamples:")
        print("  python3 enhanced_transcriber.py 'audio.m4a'")
        print("  python3 enhanced_transcriber.py 'audio.m4a' 'transcript.txt'")
        print("  python3 enhanced_transcriber.py 'audio.m4a' 'transcript.txt' 'vosk-model-en-us-0.22'")
        sys.exit(1)
    
    audio_file = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else None
    model_name = sys.argv[3] if len(sys.argv) > 3 else None
    
    transcriber = EnhancedAudioTranscriber(model_name)
    transcriber.transcribe_with_confidence(audio_file, output_file)

if __name__ == "__main__":
    main() 